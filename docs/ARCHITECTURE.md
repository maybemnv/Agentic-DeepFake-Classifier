# ğŸ§  Agentic Deepfake Classifier - How It Works

A beginner-friendly guide to understanding what we built and how all the pieces fit together.

---

## ğŸ“– The Big Picture

Think of this system like a **security guard** checking if a video is real or fake:

```
Video File
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    OUR SYSTEM                               â”‚
â”‚                                                             â”‚
â”‚  1. VIDEO PROCESSOR    â†’ Breaks video into frames           â”‚
â”‚         â†“                                                   â”‚
â”‚  2. FACE DETECTOR      â†’ Finds faces in each frame          â”‚
â”‚         â†“                                                   â”‚
â”‚  3. CLASSIFIER         â†’ Checks if each face is fake        â”‚
â”‚         â†“                                                   â”‚
â”‚  4. DECISION AGENT     â†’ Makes final verdict (Real/Fake)    â”‚
â”‚         â†“                                                   â”‚
â”‚  5. COGNITIVE AGENT    â†’ Explains the decision in English   â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
Result: "This video is FAKE with 85% confidence"
```

---

## ğŸ—‚ï¸ Project Structure Explained

```
Agentic DeepFake Classifier/
â”‚
â”œâ”€â”€ src/                          # ğŸ§  The brain of our system
â”‚   â”œâ”€â”€ analyzer.py               # Main entry point - ties everything together
â”‚   â”‚
â”‚   â”œâ”€â”€ detector/                 # ğŸ” Detection modules (finding & analyzing)
â”‚   â”‚   â”œâ”€â”€ video_processor.py    # Handles video files
â”‚   â”‚   â”œâ”€â”€ face_detector.py      # Finds faces using AI
â”‚   â”‚   â”œâ”€â”€ classifier.py         # Determines real vs fake
â”‚   â”‚   â””â”€â”€ pipeline.py           # Connects all detector modules
â”‚   â”‚
â”‚   â””â”€â”€ agents/                   # ğŸ¤– Agentic modules (decision making)
â”‚       â”œâ”€â”€ decision_agent.py     # Makes the final call
â”‚       â””â”€â”€ cognitive_agent.py    # Explains in human language
â”‚
â”œâ”€â”€ model/                        # ğŸ§ª Pre-trained AI model
â”‚   â””â”€â”€ ffpp_c23.pth              # The "brain" trained on 1M+ fake videos
â”‚
â”œâ”€â”€ yoink/Deepfake-Detection/     # ğŸ“¦ External code we're using
â”‚   â””â”€â”€ network/xception.py       # The neural network architecture
â”‚
â”œâ”€â”€ frontend/                     # ğŸ–¥ï¸ Web interface
â”‚   â””â”€â”€ app.py                    # Streamlit UI
â”‚
â””â”€â”€ main.py                       # ğŸš€ Command-line interface
```

---

## ğŸ” Each Module Explained

### 1. Video Processor (`video_processor.py`)

**What it does:** Opens a video file and extracts individual frames (images).

**Why we need it:** AI models can't process videos directly - they need individual images.

```python
# Simple example of what it does:
video = "my_video.mp4"  # 30 second video at 30 fps = 900 frames

# We don't need ALL frames, so we sample 1 per second = 30 frames
# This is much faster and still accurate!
frames = video_processor.extract_frames(video)  # Returns 30 images
```

**Key features:**

- Validates video format (MP4, AVI, etc.)
- Configurable sampling rate (default: 1 frame per second)
- Memory efficient (uses generators)

---

### 2. Face Detector (`face_detector.py`)

**What it does:** Finds human faces in each frame.

**Why we need it:** Deepfakes manipulate FACES, so we need to isolate them.

```python
# For each frame, find the face:
frame = load_image("frame_001.jpg")

face = face_detector.detect_largest_face(frame)
# Returns: cropped 299x299 image of just the face
```

**Key features:**

- Uses dlib library (industry standard for face detection)
- Scales bounding box 1.3x to capture more context around face
- Handles frames with no faces (skips them)

---

### 3. Classifier (`classifier.py`)

**What it does:** Looks at a face image and predicts if it's REAL or FAKE.

**Why we need it:** This is the actual "detection" part!

```python
# The classifier is a neural network called XceptionNet:
face_image = load_face("face_001.jpg")

result = classifier.classify(face_image)
# Returns:
#   - real_probability: 0.15 (15% chance it's real)
#   - fake_probability: 0.85 (85% chance it's fake)
```

**How it works (simplified):**

1. The XceptionNet was trained on 1,000,000+ images of real and fake faces
2. It learned to spot tiny patterns that distinguish fakes:
   - Unnatural skin textures
   - Weird lighting reflections in eyes
   - Blending artifacts around face edges
3. When you give it a new face, it compares to what it learned

**The weights file (`ffpp_c23.pth`):**

- This is the "memory" of the trained model
- Contains millions of numbers that encode what the model learned
- Without this file, the model would be useless (random guessing)

---

### 4. Pipeline (`pipeline.py`)

**What it does:** Connects Video â†’ Face â†’ Classifier into one smooth flow.

```python
# Instead of calling each module separately:
pipeline = DetectionPipeline()
analysis = pipeline.analyze_video("suspicious_video.mp4")

# Returns analysis with ALL frame results:
# - Frame 1: face detected, 82% fake
# - Frame 2: face detected, 79% fake
# - Frame 3: no face detected, skipped
# - Frame 4: face detected, 85% fake
# ... etc
```

---

### 5. Decision Agent (`decision_agent.py`)

**What it does:** Takes all the frame scores and makes ONE final decision.

**Why "agentic"?** It acts autonomously - you don't tell it what to decide, it figures it out based on rules.

```python
# The agent receives scores from all frames:
frame_scores = [0.82, 0.79, 0.85, 0.88, 0.81]  # All high = likely fake

decision = decision_agent.decide(frame_scores)
# Returns:
#   - verdict: "FAKE"
#   - confidence: 0.91 (91% sure)
```

**Decision rules (from your POC):**

| Average Fake Score | Verdict       |
| ------------------ | ------------- |
| >= 0.7 (70%)       | ğŸš¨ FAKE       |
| 0.4 to 0.7         | âš ï¸ SUSPICIOUS |
| < 0.4 (40%)        | âœ… REAL       |

**Also considers:**

- **Variance:** If scores jump around a lot (0.2, 0.9, 0.3), it's less confident
- **Sample size:** More faces analyzed = more reliable decision

---

### 6. Cognitive Agent (`cognitive_agent.py`)

**What it does:** Translates technical results into human-readable explanations.

```python
# Takes the decision:
decision = DecisionResult(verdict="FAKE", confidence=0.91, ...)

response = cognitive_agent.generate_response(decision)
# Returns:
#   verdict_text: "This video shows strong indicators of deepfake manipulation."
#   recommendation: "Do not trust this video's authenticity. Verify with original source."
```

**Why we need it:** Numbers are hard to interpret. Humans need context and advice.

---

### 7. Analyzer (`analyzer.py`)

**What it does:** The "main brain" that orchestrates everything.

```python
# This is what you actually use:
from src.analyzer import DeepfakeAnalyzer

analyzer = DeepfakeAnalyzer()
result = analyzer.analyze("video.mp4")

print(result)  # Prints everything nicely formatted
```

**It combines:**

1. Detection Pipeline (video â†’ frames â†’ faces â†’ scores)
2. Decision Agent (scores â†’ verdict)
3. Cognitive Agent (verdict â†’ explanation)

---

## ğŸ”„ Complete Flow Example

Let's trace through what happens when you analyze a video:

```
INPUT: suspicious_video.mp4 (10 seconds, 30fps)

STEP 1: Video Processor
â”œâ”€â”€ Opens video with OpenCV
â”œâ”€â”€ Extracts 10 frames (1 per second)
â””â”€â”€ Returns: [frame_0, frame_1, ..., frame_9]

STEP 2: Face Detector (for each frame)
â”œâ”€â”€ Frame 0: Found face at (120, 80), cropped to 299x299
â”œâ”€â”€ Frame 1: Found face at (125, 82), cropped to 299x299
â”œâ”€â”€ Frame 2: No face detected (person looked away)
â”œâ”€â”€ ... (continues for all frames)
â””â”€â”€ Returns: [face_0, face_1, face_3, ...]  (8 faces total)

STEP 3: Classifier (for each face)
â”œâ”€â”€ Face 0: real=0.18, fake=0.82 â†’ "FAKE"
â”œâ”€â”€ Face 1: real=0.21, fake=0.79 â†’ "FAKE"
â”œâ”€â”€ Face 3: real=0.15, fake=0.85 â†’ "FAKE"
â”œâ”€â”€ ...
â””â”€â”€ Returns: [0.82, 0.79, 0.85, 0.88, 0.81, 0.77, 0.83, 0.86]

STEP 4: Decision Agent
â”œâ”€â”€ Calculates average: 0.826 (82.6%)
â”œâ”€â”€ Checks threshold: 0.826 >= 0.7 â†’ FAKE
â”œâ”€â”€ Calculates confidence: 0.89 (89%)
â””â”€â”€ Returns: verdict=FAKE, confidence=89%

STEP 5: Cognitive Agent
â”œâ”€â”€ Looks up template for "FAKE" + "high confidence"
â”œâ”€â”€ Generates explanation with statistics
â””â”€â”€ Returns: "This video shows strong indicators of deepfake manipulation..."

OUTPUT:
============================================================
DEEPFAKE ANALYSIS RESULT
============================================================

ğŸ“ Video: suspicious_video.mp4
â±ï¸  Duration: 10.0s

ğŸš¨ VERDICT: FAKE
ğŸ“Š Confidence: 89%

--- Explanation ---
This video shows strong indicators of deepfake manipulation.

--- Technical Summary ---
â€¢ Frames analyzed: 10
â€¢ Faces detected: 8
â€¢ Avg fake score: 82.6%
â€¢ Score range: 77% - 88%

--- Recommendation ---
Do not trust this video's authenticity.
Verify with the original source if possible.
============================================================
```

---

## ğŸ§ª The AI Model Explained

### What is XceptionNet?

XceptionNet is a type of **Convolutional Neural Network (CNN)** - a special AI architecture designed for image analysis.

**Think of it like this:**

- A human learns to spot fakes by looking at thousands of examples
- XceptionNet does the same, but with millions of examples and math

**Why XceptionNet for deepfakes?**

- It was designed to find subtle patterns in images
- FaceForensics++ researchers found it works really well for deepfakes
- It's accurate AND reasonably fast

### The Pre-trained Weights (`ffpp_c23.pth`)

```
ffpp = FaceForensics++ (the dataset it was trained on)
c23 = Compression level 23 (high quality videos)
.pth = PyTorch format
```

This 83MB file contains **~22 million numbers** that represent what the model learned:

- Patterns in real faces
- Patterns in fake faces
- The differences between them

**Without this file, the model is just an empty shell that guesses randomly.**

---

## ğŸ¤– What Makes It "Agentic"?

Traditional software: "If score > 0.7, return FAKE"

**Agentic approach:**

1. **Autonomous reasoning:** The Decision Agent considers multiple factors (average, variance, sample size)
2. **Confidence awareness:** It knows when it's unsure
3. **Adaptive thresholds:** Can adjust based on context
4. **Self-explanation:** Generates its own reasoning (Cognitive Agent)

This is more like how a human expert would work - not just following rigid rules, but understanding context and explaining decisions.

---

## ğŸš€ How to Use It

### Option 1: Command Line

```bash
# Basic analysis
python main.py --video path/to/video.mp4

# Quick check (faster, less accurate)
python main.py --video path/to/video.mp4 --quick

# Save results to file
python main.py --video path/to/video.mp4 --output results.json
```

### Option 2: Streamlit Web UI

```bash
streamlit run frontend/app.py
# Then open http://localhost:8501 in your browser
```

### Option 3: Python Code

```python
from src.analyzer import DeepfakeAnalyzer

# Create analyzer (loads model once)
analyzer = DeepfakeAnalyzer()

# Analyze any video
result = analyzer.analyze("video.mp4")

# Access results
print(result.verdict)       # REAL, FAKE, SUSPICIOUS, or INCONCLUSIVE
print(result.confidence)    # 0.0 to 1.0
print(result.explanation)   # Human-readable text
```

---

## â“ Common Questions

### Q: How accurate is it?

The XceptionNet model achieves ~95% accuracy on the FaceForensics++ test set. Real-world accuracy may vary depending on:

- Video quality
- Type of deepfake
- Compression level

### Q: Can it be fooled?

Yes, adversarial attacks can sometimes fool AI detectors. This is why we:

- Analyze multiple frames
- Report confidence levels
- Recommend manual verification for important cases

### Q: Why is it slow?

The neural network processes each face through 36 convolutional layers with millions of calculations. To speed up:

- Use `--quick` flag (analyzes fewer frames)
- Use `--max-frames 10` to limit analysis
- Use GPU (`--cuda`) if available

### Q: What video formats work?

MP4, AVI, MOV, MKV, WebM

---

## ğŸ“š Key Terms Glossary

| Term             | Definition                                                     |
| ---------------- | -------------------------------------------------------------- |
| **Deepfake**     | AI-generated fake video, usually swapping faces                |
| **XceptionNet**  | Neural network architecture optimized for image classification |
| **dlib**         | Library for face detection and recognition                     |
| **CNN**          | Convolutional Neural Network - AI for processing images        |
| **Inference**    | Running a trained model to make predictions                    |
| **Weights**      | The learned parameters of a neural network                     |
| **Frame**        | A single image from a video                                    |
| **Bounding Box** | Rectangle coordinates around a detected face                   |
| **Softmax**      | Function that converts model output to probabilities           |

---

## ğŸ—ï¸ Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        USER INTERFACE LAYER                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   main.py (CLI)          â”‚        frontend/app.py (Streamlit)         â”‚
â”‚   - Command line args    â”‚        - File upload                       â”‚
â”‚   - JSON output          â”‚        - Visual results                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚                            â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         ANALYZER (src/analyzer.py)                      â”‚
â”‚                    Orchestrates the entire flow                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â–¼               â–¼               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Detection       â”‚ â”‚ Decision   â”‚ â”‚ Cognitive       â”‚
â”‚ Pipeline        â”‚ â”‚ Agent      â”‚ â”‚ Agent           â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚            â”‚ â”‚                 â”‚
â”‚ â”‚Video Proc.  â”‚ â”‚ â”‚ Scores â†’   â”‚ â”‚ Decision â†’      â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚ Verdict    â”‚ â”‚ Explanation     â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚            â”‚ â”‚                 â”‚
â”‚ â”‚Face Detect. â”‚ â”‚ â”‚ Thresholds â”‚ â”‚ Templates       â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚ Confidence â”‚ â”‚ Recommendations â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚            â”‚ â”‚                 â”‚
â”‚ â”‚Classifier   â”‚ â”‚ â”‚            â”‚ â”‚                 â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚            â”‚ â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    MODEL LAYER (yoink/Deepfake-Detection/)              â”‚
â”‚                                                                         â”‚
â”‚   network/xception.py  â†â†’  model/ffpp_c23.pth (weights)                â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

_Created for the Agentic Deepfake Classifier POC_
